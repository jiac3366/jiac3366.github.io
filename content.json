{"meta":{"title":"Hexo","subtitle":"","description":"","author":"Jiaccc","url":"https://jiac3366.github.io","root":"/"},"pages":[{"title":"友情链接","date":"2021-09-15T13:19:16.012Z","updated":"2021-09-15T13:19:16.012Z","comments":true,"path":"links/index.html","permalink":"https://jiac3366.github.io/links/index.html","excerpt":"","text":""},{"title":"标签","date":"2021-09-15T13:19:16.013Z","updated":"2021-09-15T13:19:16.013Z","comments":false,"path":"tags/index.html","permalink":"https://jiac3366.github.io/tags/index.html","excerpt":"","text":""},{"title":"分类","date":"2021-09-15T13:19:16.011Z","updated":"2021-09-15T13:19:16.011Z","comments":false,"path":"categories/index.html","permalink":"https://jiac3366.github.io/categories/index.html","excerpt":"","text":""},{"title":"404 Not Found：该页无法显示","date":"2021-09-15T14:01:41.464Z","updated":"2021-09-15T13:19:16.010Z","comments":false,"path":"/404.html","permalink":"https://jiac3366.github.io/404.html","excerpt":"","text":""},{"title":"Repositories","date":"2021-09-15T13:19:16.012Z","updated":"2021-09-15T13:19:16.012Z","comments":false,"path":"repository/index.html","permalink":"https://jiac3366.github.io/repository/index.html","excerpt":"","text":""},{"title":"关于","date":"2021-09-15T13:19:16.011Z","updated":"2021-09-15T13:19:16.011Z","comments":false,"path":"about/index.html","permalink":"https://jiac3366.github.io/about/index.html","excerpt":"","text":"个人详细介绍"}],"posts":[{"title":"","slug":"mysql_OK/14 数据备份","date":"2021-10-21T16:15:16.883Z","updated":"2021-10-21T16:15:16.883Z","comments":true,"path":"2021/10/22/mysql_OK/14 数据备份/","link":"","permalink":"https://jiac3366.github.io/2021/10/22/mysql_OK/14%20%E6%95%B0%E6%8D%AE%E5%A4%87%E4%BB%BD/","excerpt":"","text":"物理备份：收费 逻辑备份： musqldump 备份数据库的表mysqldump -u root -p demo goodsmaster membermaster &gt; test.sql (存的是表信息，恢复时要先有数据库) 备份数据库mysqldump -u root -p –databases demo demo1 &gt; test1.sql 以一定格式保存和导入数据， mysql&gt; SELECT * INTO OUTFILE ‘C:/ProgramData/MySQL/MySQL Server 8.0/Uploads/goodsmaster.txt’-&gt; FIELDS TERMINATED BY ‘,’-&gt; LINES TERMINATED BY ‘\\n’-&gt; FROM demo.goodsmaster; （C:/ProgramData/MySQL/MySQL Server 8.0/Uploads是配置文件 my.ini “secure-file-priv”参数的设定） mysql&gt; LOAD DATA INFILE ‘C:/ProgramData/MySQL/MySQL Server 8.0/Uploads/goodsmaster.txt’-&gt; INTO TABLE demo.goodsmaster-&gt; FIELDS TERMINATED BY ‘,’-&gt; LINES TERMINATED BY ‘\\n’;LOAD DATA 速度很快 数据恢复工具 mysql 看上一节 SOURCE 文件名，要进去mysql再执行","categories":[],"tags":[]},{"title":"日志","slug":"mysql_OK/13 日志","date":"2021-10-21T16:15:16.882Z","updated":"2021-10-21T16:15:16.883Z","comments":true,"path":"2021/10/22/mysql_OK/13 日志/","link":"","permalink":"https://jiac3366.github.io/2021/10/22/mysql_OK/13%20%E6%97%A5%E5%BF%97/","excerpt":"","text":"MySQL 日志包括通用查询日志、慢查询日志、错误日志、二进制日志、中继日志、重做日志和回滚日志 通用查询日志记录了所有用户的连接开始时间和截止时间，以及发给 MySQL 数据库服务器的所有 SQL 指令，还原操作时的具体场景，帮助我们了解操作发生的具体时间和操作的细节 show variables like ‘%general%’; SET GLOBAL general_log = ‘ON’; SET @@global.general_log_file = ‘mytest.log’; 慢查询日志 show variables like ‘min%’; long_query_time=10 和 min_examined_row_limit=0 共同判断：只要查询时间和扫描行数大于这2值就记录慢日志 错误日志（排障首选） 错误日志文件中记录了服务器启动的时间，以及存储引擎 InnoDB 启动和停止的时间等。 默认是开启，可以在mysql配置文件“my.ini”中配置 二进制日志记录数据库的更新事件 查询和删除： 正在写入的二进制日志 SHOW MASTER STATUS; 所有的二进制日志 SHOW BINARY LOGS; 二进制日志中所有数据更新事件: SHOW BINLOG EVENTS IN 二进制文件名; ??? 重新开一个新的日志文件记录binlog FLUSH BINARY LOGS; 删除 RESET MASTER; 删除比指定二进制日志文件编号小的所有二进制日志文件 SQL：PURGE MASTER LOGS TO ‘GJTECH-PC-bin.000005’; 利用mysqldump和binlog恢复数据 1、数据库外执行：mysqldump -u root -p album &gt; newbackup.sql（还可以-h指定数据服务器名称） 2、flush binary logs 3、发生宕机，检查确定要哪些binlog，因为超过系统变量 max_binlog_size 指定的值时，系统就会生成一个新的二进制日志文件) 4、flush binary logs，与上一条刷新log对应组成的作用是，独立保留下全量备份到宕机时段的binlog文件，是防止后面数据恢复的事件被写入最新的二进制日志文件，妨碍理解文件的内容。 5、重建DB， 6、数据库外执行：mysql -u root -p django_album &lt; newbackup.sql 这时全量备份已恢复 7、show binlog events in ‘binlog.000007’; 查看找到最新的begin起始位置？这里假设是318 8、数据库外执行：mysqlbinlog –start-position=318 “/var/lib/mysql/binlog.000007” | mysql -u root -pmysqlbinlog –start-positon=xxx –end-position=yyy 二进制文件名 | mysql -u 用户 -p 中继日志 主从架构中，为了与主服务器保持一致，要把主服务器的二进制日志写入到从服务器本地的日志，这个日志文件叫中继日志，格式：从服务器名-relay-bin. 序号. 有坑：中继日志里包含主从服务器的host，重装系统记得改回之前的host 回滚日志 undo log 用于事务回滚 使其他事务读取到这个事务修改数据前的值 默认大小1G 下列变量定义了回滚日志所在的文件夹、是否加密、是否自动截断回收空间（有效的前提是设置了独立表空间）和是否有独立的表空间（放单独一个文件的意思？） 重做日志 redolog 系统遇到故障的恢复过程中，可以修复被未完成的事务修改的数据. 宕机或者停电等异常情况导致内存保存的数据更新操作丢失，可以通过读取重做日志中记录的数据更新操作，把没来得及写到磁盘上的数据更新写到磁盘上，确保数据的完整性. SHOW VARIABLES LIKE ‘%innodb_log_files_in_group%’ 查看重做日志的数量，取值为1-4，用于记录不同的操作 1 用户创建表的插入操作 2 用户创建表的更新和删除操作 3 临时表的插入操作 4 临时表的更新和删除操作 总结： 二进制日志：增量信息，分库分表场景很麻烦，难以确定起止位置，解决方案可以是配置主从架构，靠中继日志在从DB备份 中继日志：从服务器用来存放主服务器二进制日志内容的一个中间文件，用于同步主服务器数据 回滚日志？：存事务数据更新前的状态，以便回滚 重做日志：是为了确保数值持久性、防止数据更新丢失的一种日志 课后习题： mysql&gt; SHOW BINLOG EVENTS IN ‘GJTECH-PC-bin.000013’;+———————-+——+—————-+———–+————-+————————————–+| Log_name | Pos | Event_type | Server_id | End_log_pos | Info |+———————-+——+—————-+———–+————-+————————————–+| GJTECH-PC-bin.000013 | 556 | Query | 1 | 627 | BEGIN || GJTECH-PC-bin.000013 | 627 | Table_map | 1 | 696 | table_id: 114 (demo.goodsmaster) || GJTECH-PC-bin.000013 | 696 | Delete_rows | 1 | 773 | table_id: 114 flags: STMT_END_F || GJTECH-PC-bin.000013 | 773 | Xid | 1 | 804 | COMMIT /* xid=253 / || GJTECH-PC-bin.000013 | 804 | Anonymous_Gtid | 1 | 894 | SET @@SESSION.GTID_NEXT= ‘ANONYMOUS’ || GJTECH-PC-bin.000013 | 894 | Query | 1 | 969 | BEGIN || GJTECH-PC-bin.000013 | 969 | Table_map | 1 | 1038 | table_id: 114 (demo.goodsmaster) || GJTECH-PC-bin.000013 | 1038 | Write_rows | 1 | 1094 | table_id: 114 flags: STMT_END_F || GJTECH-PC-bin.000013 | 1094 | Xid | 1 | 1125 | COMMIT / xid=259 */ | 其中包括了哪几个 SQL 数据操作呢？为了从二进制日志中恢复这些操作，我们应该如何设置起始位置和截止位置呢？A:这段二进制日志包括了2个SQL操作，第一个是从数据表demo.goodsmaster中删除一条记录，第二个是向数据表demo.goodsmaster中插入一条记录。起始位置：627，截止位置：1125","categories":[{"name":"MySQL必知必会","slug":"MySQL必知必会","permalink":"https://jiac3366.github.io/categories/MySQL%E5%BF%85%E7%9F%A5%E5%BF%85%E4%BC%9A/"}],"tags":[]},{"title":"数学计算 字符串处理","slug":"mysql_OK/9 数学计算 字符串处理","date":"2021-10-20T00:53:21.034Z","updated":"2021-10-20T00:53:21.035Z","comments":true,"path":"2021/10/20/mysql_OK/9 数学计算 字符串处理/","link":"","permalink":"https://jiac3366.github.io/2021/10/20/mysql_OK/9%20%E6%95%B0%E5%AD%A6%E8%AE%A1%E7%AE%97%20%E5%AD%97%E7%AC%A6%E4%B8%B2%E5%A4%84%E7%90%86/","excerpt":"","text":"大部分 DBMS 会有自己特定的函数，SQL 函数的代码可移植性很差 数学函数 向上取整 CEIL(X) 和 CEILING(X) 向下取整 FLOOR(X) 舍入函数 ROUND(X,D)ROUND(X) 表示保留 0 位小数。 字符串函数 使用示例查看10.","categories":[{"name":"MySQL必知必会","slug":"MySQL必知必会","permalink":"https://jiac3366.github.io/categories/MySQL%E5%BF%85%E7%9F%A5%E5%BF%85%E4%BC%9A/"}],"tags":[]},{"title":"时间函数","slug":"mysql_OK/8 时间函数","date":"2021-10-20T00:53:21.033Z","updated":"2021-10-20T00:53:21.033Z","comments":true,"path":"2021/10/20/mysql_OK/8 时间函数/","link":"","permalink":"https://jiac3366.github.io/2021/10/20/mysql_OK/8%20%E6%97%B6%E9%97%B4%E5%87%BD%E6%95%B0/","excerpt":"","text":"很多人把时间日期的相关计算放到编程语言层面去处理 获取日期时间数据中部分信息的函数 需求：统计一天中每小时的销售数量和销售金额 第2行也可以改成 HOUR(b.transdate) AS 时段,过程如下： 从交易时间中抽取小时信息：EXTRACT(HOUR FROM b.transdate)； 按交易的小时信息分组； 按分组统计销售数量和销售金额的和； 按交易的小时信息排序。 计算日期时间的函数 DATE_ADD（date, INTERVAL 表达式 type） DATE_ADD() 来计算从某个时间点开始，过去或者未来一个时间间隔的时间 LAST_DAY（date）获得某个时间节点当月的最后一天的日期 eg:今天是 2020 年 12 月 10 日，计算与去年同期相比的增长率从2020.12.10到2019.12.01——SELECT DATE_ADD( LAST_DAY( DATE_ADD( DATE_ADD( &#39;2020-12-10&#39;, INTERVAL - 1 YEAR ), INTERVAL - 1 MONTH )), INTERVAL 1 DAY ); 其他日期时间函数 获取当前的日期：CURDATE（） 把日期按照一定的格式显示： DATE_FORMAT(date, %xx) ,xx有很多种格式 DATEDIFF（date1,date2），表示日期“date1”与日期“date2”之间差几天。 获取日期“date”是周几：DAYOFWEEK（date） SELECTCASE DAYOFWEEK(CURDATE()) - 1 WHEN 0 THEN 7 ELSE DAYOFWEEK(CURDATE()) - 1 END CASE;","categories":[{"name":"MySQL必知必会","slug":"MySQL必知必会","permalink":"https://jiac3366.github.io/categories/MySQL%E5%BF%85%E7%9F%A5%E5%BF%85%E4%BC%9A/"}],"tags":[]},{"title":"","slug":"mysql_OK/7聚合函数","date":"2021-10-20T00:53:21.032Z","updated":"2021-10-20T00:53:21.032Z","comments":true,"path":"2021/10/20/mysql_OK/7聚合函数/","link":"","permalink":"https://jiac3366.github.io/2021/10/20/mysql_OK/7%E8%81%9A%E5%90%88%E5%87%BD%E6%95%B0/","excerpt":"","text":"MAX（）和 MIN（）计算出的结果不一定是同一条记录的数据 COUNT( ) 如果 COUNT（*）与 GROUP BY 一起使用，就表示统计分组内有多少条数据。它也可以单独使用，这就相当于数据集全体是一个分组，统计全部数据集的记录数 COUNT（字段）用来统计分组内这个字段的值(非空值)出现了多少次。如果字段值是空，就不统计。使用场景：统计表中字段的非空值 课后： 在商品信息表中，哪种商品的商品名称有重复，分别重复了几次？ select COUNT(column_name) as column_as from table_name group by column_as having now_count&gt;1;","categories":[],"tags":[]},{"title":"WHERE和HAVING","slug":"mysql_OK/6WHERE和HAVING","date":"2021-10-20T00:53:21.031Z","updated":"2021-10-20T00:53:21.031Z","comments":true,"path":"2021/10/20/mysql_OK/6WHERE和HAVING/","link":"","permalink":"https://jiac3366.github.io/2021/10/20/mysql_OK/6WHERE%E5%92%8CHAVING/","excerpt":"","text":"需要查询出一个商品记录集，限定条件是单笔销售金额超过 50 元–&gt;2者结果一样 WHERE——先从数据表 demo.transactiondetails 中抽取满足条件“a.salesvalue&gt;50，然后连接goodsmaster，再DISTINCT也就是先限定金额&gt;50的流水，再把商品名字加过去 HAVING查询过程—— 先把有关的信息从关联表都连接好 对数据集进行分组，形成一个包含所有需要的信息的数据集合 通过 HAVING 条件的对集合筛选，得到需要的数据 WHERE和HAVING区别：如果需要通过连接从关联表中获取需要的数据，WHERE 是先筛选后连接，而 HAVING 是先连接后筛选。 WHERE 比 HAVING 更高效 HAVING 必须要与 GROUP BY 配合使用，特点是可以把分组计算的函数作为筛选条件，而WHERE运行在GROUP BY前，它无法做到这样的查询。 2者不互斥——要查询“2020-12-10”和“2020-12-11”这两天收银金额超过 100 元的销售日期、收银员名称、销售数量和销售金额。","categories":[{"name":"MySQL必知必会","slug":"MySQL必知必会","permalink":"https://jiac3366.github.io/categories/MySQL%E5%BF%85%E7%9F%A5%E5%BF%85%E4%BC%9A/"}],"tags":[]},{"title":"外键与连接","slug":"mysql_OK/5外键和连接","date":"2021-10-20T00:53:21.029Z","updated":"2021-10-20T00:53:21.030Z","comments":true,"path":"2021/10/20/mysql_OK/5外键和连接/","link":"","permalink":"https://jiac3366.github.io/2021/10/20/mysql_OK/5%E5%A4%96%E9%94%AE%E5%92%8C%E8%BF%9E%E6%8E%A5/","excerpt":"","text":"在 MySQL 中，外键是通过外键约束来定义的。外键约束就是约束的一种，它必须在从表 中定义，包括指明哪个是外键字段，以及外键字段所引用的主表中的主键字段是什么。 MySQL 若发现要删除的主表记录正在被从表中某条记录的外键字段所引用，就会提示错误 用到 MySQL 自带的、用于存储系统信息的数据库：information_schema。我们可以查看外键约束的相关信息 创建外键约束 修改表定义外键约束ALTER TABLE 从表名 ADD CONSTRAINT 约束名 FOREIGN KEY 字段名 REFERENCES 主表名 （字段名） 外键约束不是关联查询的必要条件，MySQL 允许你不使用系统自带的外键约束，在应用层面完成检查数据一致性的逻辑，提高性能。但是有了它，MySQL 系统会保护你的数据，避免出现误删的情况，从而提高系统整体的可靠性。（进货数据拆成了 2 个表，这就决定了无论是数据添加，还是数据删除，都不能通过一条 SQL 语句实现，完全有可能只执行了一部分） 课后：","categories":[{"name":"MySQL必知必会","slug":"MySQL必知必会","permalink":"https://jiac3366.github.io/categories/MySQL%E5%BF%85%E7%9F%A5%E5%BF%85%E4%BC%9A/"}],"tags":[]},{"title":"主键知识","slug":"mysql_OK/4 主键","date":"2021-10-20T00:53:21.028Z","updated":"2021-10-20T00:53:21.028Z","comments":true,"path":"2021/10/20/mysql_OK/4 主键/","link":"","permalink":"https://jiac3366.github.io/2021/10/20/mysql_OK/4%20%E4%B8%BB%E9%94%AE/","excerpt":"","text":"尽量不用业务字段作主键主要原因还是业务字段会存在复用或重复，例如说这个主键是会员号，这个会员卡因为回收会员号的信息是另外一个人，这样导致交易流水表外键链接到的会员卡号真正的信息也换了一个人 小项目1：把原来业务主键改为自增主键，并在流水表设置新的外键链接到自增主键 删除主键约束，增加自增主键 修改外表 再次复用主键，流水表查询结果： 多台服务器情况下，自增主键带来的问题：如何合并相同id的数据，如果 系统比较复杂尽量给表加一个字段做主键，采用手动赋值的办法，虽然系统开发的 时候麻烦一点，却可以避免后面出大问题。 取消id字段的自增属性，把当前会员编号的最大值记录在总server管理信息表 门店在添加会员的时候，先到总server 中获取这个最大值，在这个基础上加1，然后用这个值作为新会员的“id”，同时，更新总server 管理信息表中的当前会员编号的最大值 我他吗终于整明白了 课后作业：把销售流水表 demo.trans 中，所有单位是“包”的商品的价格改成原来价格的 80% update domo.trans set price = price * 0.8 where itemnumber in (select itemnumber from demo.goodsmaster where unit = ‘包’);","categories":[{"name":"MySQL必知必会","slug":"MySQL必知必会","permalink":"https://jiac3366.github.io/categories/MySQL%E5%BF%85%E7%9F%A5%E5%BF%85%E4%BC%9A/"}],"tags":[]},{"title":"CRUD","slug":"mysql_OK/3 增删查改","date":"2021-10-20T00:53:21.026Z","updated":"2021-10-20T00:53:21.027Z","comments":true,"path":"2021/10/20/mysql_OK/3 增删查改/","link":"","permalink":"https://jiac3366.github.io/2021/10/20/mysql_OK/3%20%E5%A2%9E%E5%88%A0%E6%9F%A5%E6%94%B9/","excerpt":"","text":"把查询结果插入到数据表中 insert into table1 (xx,) select xx, from table2 where condition 不要随便修改表的主键，否则会破坏数据完整性 FROM 后面的是数据源，可以把一个查询结果数据集当做一个虚拟的数据表（数据源）来看待，MySQL 规定，必须要用 AS 关键字给这个派生表起一个别名 ORDER BY barcode ASC,price DESC，查询结果会先按照字段 barcode 的升序排序，相同 barcode 里面的字段，按照 price 的降序排序 LIMIT 1,2,就表示从第 2 条数据开始(下标为1)，显示 2 条数据，也就是显示了第 2、3 条数据 合并2个表的数据，并且处理重复的商品编号 课后问题：?? 如果我删除了一条记录，再次插入数据的时候，就会出现字段“itemnumber”（自增主键id）的值不连续的情况。请你想一想，如何插入数据，才能防止这种情况的发生呢？ A:，在应用层面设计一个模块，专门来处理主键ID的计算，解决唯一性，不连续 等问题。","categories":[{"name":"MySQL必知必会","slug":"MySQL必知必会","permalink":"https://jiac3366.github.io/categories/MySQL%E5%BF%85%E7%9F%A5%E5%BF%85%E4%BC%9A/"}],"tags":[]},{"title":"修改表结构","slug":"mysql_OK/2 修改表结构","date":"2021-10-20T00:53:21.025Z","updated":"2021-10-20T00:53:21.025Z","comments":true,"path":"2021/10/20/mysql_OK/2 修改表结构/","link":"","permalink":"https://jiac3366.github.io/2021/10/20/mysql_OK/2%20%E4%BF%AE%E6%94%B9%E8%A1%A8%E7%BB%93%E6%9E%84/","excerpt":"","text":"把原来的表结构复制 CREATE TABLE demo.importheadhist LIKE demo.importhead; 查看表结构 DESCRIBE demo.importheadhist; 向表中添加一个字段，我们甚至可以指定添加字段在表中的位置 ALTER TABLE demo.importheadhist ADD suppliername TEXT AFTER supplierid; 把字段改为不可重复 ALTER TABLE demo.goodsmaster MODIFY salesprice INT UNIQUE;","categories":[{"name":"MySQL必知必会","slug":"MySQL必知必会","permalink":"https://jiac3366.github.io/categories/MySQL%E5%BF%85%E7%9F%A5%E5%BF%85%E4%BC%9A/"}],"tags":[]},{"title":"临时表","slug":"mysql_OK/11 临时表","date":"2021-10-20T00:53:21.022Z","updated":"2021-10-20T00:53:21.022Z","comments":true,"path":"2021/10/20/mysql_OK/11 临时表/","link":"","permalink":"https://jiac3366.github.io/2021/10/20/mysql_OK/11%20%E4%B8%B4%E6%97%B6%E8%A1%A8/","excerpt":"","text":"我们用的都是外部临时表，内部临时表系统自动产生使用 为临时表是连接隔离的，不同的连接可以使用相同的临时表名称,临时表会在连接结束的时候自动删除，不会占用磁盘空间 CREATE TEMPORARY TABLE 表名 ( 字段名 字段类型, … )ENGINE = MEMORY; （若设置ENGINE = MEMORY：临时表数据存在内存中，不加默认存在磁盘上）; 项目：查询 2020 年 12 月的一些特定商品销售数量、进货数量、返厂数量先把销售、进货、返厂3 个模块分开计算，用临时表来存储中间计算的结果，最后合并在一起|最后左连接的代码中，为什么要使用 having 而不使用 where 呢？ 如果用WHERE，会提示筛选条件中的字段不存在。而HAVING是生成结果集后进行筛选，所以可以用重命名之后的字段名进行筛选。 或者最后一行可以改成WHERE b.quantity &gt; 0 OR c.quantity &gt; 0 OR d.quantity &gt; 0; 课后习题： 非官方","categories":[{"name":"MySQL必知必会","slug":"MySQL必知必会","permalink":"https://jiac3366.github.io/categories/MySQL%E5%BF%85%E7%9F%A5%E5%BF%85%E4%BC%9A/"}],"tags":[]},{"title":"索引","slug":"mysql_OK/10 索引","date":"2021-10-20T00:53:21.021Z","updated":"2021-10-20T00:53:21.021Z","comments":true,"path":"2021/10/20/mysql_OK/10 索引/","link":"","permalink":"https://jiac3366.github.io/2021/10/20/mysql_OK/10%20%E7%B4%A2%E5%BC%95/","excerpt":"","text":"有了索引，mysql在索引中而不是数据表中寻找满足条件的索引记录，再通过索引记录中的指针来定位数据表中的数据 索引语法——表设定主键约束或者唯一性约束的时候，MySQL 会自动创建主键索引或唯一性索引 CREATE INDEX 索引名 ON TABLE 表名 (字段(N)); –这里的N，表示用前N位数据创建索引 CREATE TABLE 表名 ( 字段 数据类型, …. { INDEX | KEY } 索引名(字段) ) ALTER TABLE 表名 ADD { INDEX | KEY } 索引名 (字段); DROP INDEX 索引名 ON 表名; 删除主键索引比较特殊：ALTER TABLE 表名 DROP PRIMARY KEY； EXPLAIN 查看 SQL 语句的执行细节 possible_keys显示有 多少个索引可以用，优化器发现，xx索引实际搜索的记录数最少，所以最后就选择了这种索引，如果有多个索引，而这些索引的字段同时作为筛选字段出现在查询中的时候，MySQL 会选择使用最优的索引来执行查询操作. 能不能让这几个筛选字段同时发挥作用呢？这就用到组合索引，MySQL 最多支持由 16 个字段组成的组合索引，相关语法类似.CREATE INDEX Index_branchnumber_cashiernumber_itemnumber ON demo.trans(字段1，字段2，字段3) 组合索引的多个字段是有序的，筛选条件要遵循从左向右原则，上述查询条件如果改成“cashiernumber = 1 AND itemnumber = 100”，最左边的字段 branchnumber 没有包含到条件当中，中断了 “branchnumber &gt; 10 AND cashiernumber = 1 AND itemnumber = 100”这个条件，只能用到组合索引中 branchnumber&gt;10 的部分 如果只用组合索引的一部分，效果没有单字段索引那么好。为啥？ 课后问题：假如我有一个单品销售统计表，包括门店编号、销售日期（年月日）、商品编号、销售数量、销售金额、成本、毛利，而用户经常需要对销售情况进行查询，你会对这个表建什么样的索引呢？ A：先创建单字段索引，使用率比较高；然后选择建立（[门店编号]，商品编号，销售日期）的联合索引，考虑把门店编号放在最前面，原因是一般查询会遵循从大范围到小范围逐步递进的原则，销售日期一般是范围，放在末位直接扫链表效果较好 原则：按照字段在查询条件中使用的频度高低，从左到右顺序创建组合索引；等值查询字段尽量放在前面；范围查询放后面","categories":[{"name":"MySQL必知必会","slug":"MySQL必知必会","permalink":"https://jiac3366.github.io/categories/MySQL%E5%BF%85%E7%9F%A5%E5%BF%85%E4%BC%9A/"}],"tags":[]},{"title":"字段类型","slug":"mysql_OK/1 字段类型","date":"2021-10-20T00:53:21.019Z","updated":"2021-10-20T00:53:21.019Z","comments":true,"path":"2021/10/20/mysql_OK/1 字段类型/","link":"","permalink":"https://jiac3366.github.io/2021/10/20/mysql_OK/1%20%E5%AD%97%E6%AE%B5%E7%B1%BB%E5%9E%8B/","excerpt":"","text":"整数类型 INT 浮点数类型 FLOAT &amp; DOUBLE浮点数类型是把十进制数转换成二进制数存储 缺点： 不精准，二进制的方式来进行存储的。比如 9.625，用二进制来表达，就是1001.101，或者表达成 1.001101×2^3。如果尾数不是 0 或 5（比如9.624），就无法用一个二进制数来精确表达。 无符号数取值范围，只相当于有符号数取值范围的一半。所谓的无符号数取值范围，其实就是有符号数取值范围大于等于零的部分。 定点数类型：DECIMALDECIMAL把十进制数的整数部分和小数部分拆开，分别转换成十六进制数,用 DECIMAL（M,D）的方式表示高精度小数。其中，M 表示整数部分加小数部分一共有多少位，M&lt;=65。D 表示小数部分位数，D&lt;M 缺点： 在一些对精度要求不高的场景下，比起占用同样的字节长度的定点数，浮点数表达的数值范围可以更大一些。 文本类型 TEXT类型由于实际存储的长度不确定，MySQL 不允许TEXT 类型的字段做主键。遇到这种情况，你只能采用 CHAR(M)，或者VARCHAR(M)。只要不是主键字段，建议按照数据可能的最大长度，选择以下TEXT 类型中的的一种，作为存储字符串的数据类型。 日期与时间类型建议用DATETIME类型，虽然占用的存储空间最多，但是它表达的时间最为完整，取值范围也最大 约束 主键约束，只有1个，自动满足非空约束，可能被重用、为空、不能确保唯一的键不适合当主键 外键约束 非空约束 唯一约束，可以为空值，但只能有一条记录为空？ 自增约束，不会重复，但系统会在所有记录自增键最大值的基础之上加1","categories":[{"name":"MySQL必知必会","slug":"MySQL必知必会","permalink":"https://jiac3366.github.io/categories/MySQL%E5%BF%85%E7%9F%A5%E5%BF%85%E4%BC%9A/"}],"tags":[]},{"title":"视图","slug":"mysql_OK/12 视图","date":"2021-10-16T09:51:45.685Z","updated":"2021-10-16T10:09:06.571Z","comments":true,"path":"2021/10/16/mysql_OK/12 视图/","link":"","permalink":"https://jiac3366.github.io/2021/10/16/mysql_OK/12%20%E8%A7%86%E5%9B%BE/","excerpt":"","text":"视图 为了减少冗余数据，数据放在不同表，但是有些查询是要关联表，所以为了方便可以用视图把这种关联的结果存起来 CREATE [OR REPLACE] VIEW 视图名称 [(字段列表)] AS 查询语句 ALTER VIEW 视图名 AS 查询语句; 查看视图：DESCRIBE 视图名 DROP VIEW 视图名; 在视图中插入或删除数据：只有视图中的字段跟实际数据表中的字段完全一样，MySQL 才允许通过视图删除和修改，不一样就修改视图插入数据。但不建议对视图的数据进行更新操作 优点： 安全，用户不需要查询数据表，可以直接通过视图获取数据表中的信息 不存储数据，不占用数据存储的资源 查询模块化，把视图看成一张表来查询 视图的数据表结构相对原表可以独立，比如原表删除的字段视图可以弄个“零值”的同名字段保持查询结构 缺点： 增加维护的成本：如果实际数据表的结构变更了，我们就需要及时对相关的视图进行相应的维护。特别是当视图是由视图生成的时候（不建议使用），维护会变得比较复杂。因为创建视图的 SQL 查询可能会对字段重命名，也可能包含复杂的逻辑。 课后习题：见文件14","categories":[{"name":"MySQL必知必会","slug":"MySQL必知必会","permalink":"https://jiac3366.github.io/categories/MySQL%E5%BF%85%E7%9F%A5%E5%BF%85%E4%BC%9A/"}],"tags":[]},{"title":"Docker容器知识汇总","slug":"Docker知识汇总","date":"2021-10-14T15:51:55.571Z","updated":"2021-10-14T16:05:12.304Z","comments":true,"path":"2021/10/14/Docker知识汇总/","link":"","permalink":"https://jiac3366.github.io/2021/10/14/Docker%E7%9F%A5%E8%AF%86%E6%B1%87%E6%80%BB/","excerpt":"","text":"容器 = rootfs(静态视图) + Ns和Cgroups(动态视图) Namespace docker创建容器进程时，实际是指定了这个进程所需要启用的一组 Namespace 参数，是一种特殊的进程 int pid = clone(main_function, stack_size, CLONE_NEWPID | SIGCHLD, NULL); 隔离的Namespace中的一些命令比如ping，netstat不受docker控制，容器是单进程意思是只有1个进程是可控的 缺点：共享宿主机内核，win容器应该不能在linux跑 Cgroup CPU/Memory watch ‘ps -aux|grep malloc|grep -v grep’ 查看正在分配内存的应用，这个应用的二进制文件名叫malloc 缺点： 提及最多的自然是 /proc 文件系统，/proc 文件系统不了解 Cgroups 限制的存在容器里执行 top 指令，显示的信息居然是宿主机的 CPU 和内存数据 课后问题：如何修复容器中的 top 指令以及 /proc 文件系统中的信息 A：top 是从 /prof/stats 目录下获取数据，所以道理上来讲，容器不挂载宿主机的该目录就可以了。lxcfs就是来实现这个功能的，做法是把宿主机的 /var/lib/lxcfs/proc/memoinfo 文件挂载到Docker容器的/proc/meminfo位置后。容器中进程读取相应文件内容时，LXCFS的FUSE实现会从容器对应的Cgroup中读取正确的内存限制.（改变容器top读取数据的位置） Mount ns Mount ns跟其他 ns略有不同：它对容器进程视图的改变，一定是伴随着挂载操作（mount）才能生效。但我们希望的是：每当创建一个新容器时看到的文件系统就是一个独立的隔离环境，而不是默认继承自宿主机的文件系统。 Mount ns 对 chroot 的不断改良，做到默认挂载一个宿主机目录到容器根目录 chroot $HOME/test /bin/bash使用 $HOME/test 目录作为 /bin/bash进程(容器进程)的根目录 目前，为了容器根目录更真实，一般挂载一个完整操作系统的文件系统（比如 Ubuntu16.04 的 ISO）——“容器镜像”，更专业就叫rootfs（根文件系统）。rootfs 只是一个操作系统所包含的文件、配置和目录，并不包括操作系统内核，所以容器镜像不含内核，同一台机器上的所有容器，都共享宿主机操作系统的内核 Docker核心原理就是为待创建的用户进程： 启用 Linux Namespace 设置指定的 Cgroups 参数 切换进程的根目录（Change Root）–优先用系统调用pivot_root ，没有就用chroot Union FS 联合文件系统 AuFS: 镜像的层（5个）都放置在 /var/lib/docker/aufs/diff 目录下，然后被联合挂载（1个）在 /var/lib/docker/aufs/mnt 里面 ？？？？例子中的可读写层 ID 6e3be5d2ecccae7怎么来的 5合1是如何做到的？信息记录在 /sys/fs/aufs 通过cat /proc/mounts| grep aufs找到/var/lib/docker/aufs/mnt/id 这个id（例子中的6e3be5d2ecccae7）的挂载信息，得到si=972c6d361e6b32ba 再通过cat /sys/fs/aufs/si_972c6d361e6b32ba/br[0-9]*得到 这就是宿主机存放这个镜像的层的真正文件 OverlayFS docker创新点：设计了增量rootfs，用到了Union FS rootfs由三部分组成 读写层（容器层），是专门用来存放你修改 rootfs 后产生的增量，无论是增、删、改，会被提交到hub被其他人使用 Init层（在2大层中间），专门用来存放 /etc/hosts、/etc/resolv.conf 等，不会提交，仅对当前容器有效 只读层（镜像层） 删除只读层：要删除只读层里一个名叫 foo 的文件，实际上是在可读写层创建了一个名叫.wh.foo 的文件。这样，当这两个层被联合挂载之后，foo 文件就会被.wh.foo 文件“遮挡”起来，“消失”了，即“ro+whiteout”的方式 修改只读层：找到，就复制到容器层中，修改，修改的结果就会作用到下层的文件。即“copy on write”的方式 Dockerfile 问题：SHELL 和 VOLUME命令 CMD和ENTRYPOINTT Docker 会为你提供一个隐含的 ENTRYPOINT，即：/bin/sh -c.不指定 ENTRYPOINT 时，CMD 的内容就是 ENTRYPOINT 的参数，实际上运行在容器里的完整进程是：/bin/sh -c CMD 每个原语执行后，都会生成一个对应的镜像层。即使原语本身并没有明显地修改文件的操作（比如，ENV 原语），它对应的层也会存在。只不过在外界看来，这个层是空的 docker commit 提交增量更新 这里你对镜像roofs做的修改就是copt-on-write，init层避免了 Docker 对 /etc/hosts 等文件做的修改也一起提交. 它发生在宿主机空间，由于 Mount ns的隔离作用，宿主机不知道有目录绑定到容器中，也就是说，宿主机认为容器中可读写层的 /test 目录（/var/lib/docker/aufs/mnt/[可读写层 ID]/test），始终是空的 docker exec原理： 加入到一个某个进程已有的 Namespace 当中，达到“进入”这个进程所在容器的目的 docker inspect –format ‘‘ [容器id] ——查看容器进程iddocker inspect [容器id] | grep -I pid ls -l /proc/容器进程id/ns ——查看这个容器真实的 Namespace 文件, 这样就可以依靠系统调用做有意义的事了 系统调用：setns()，可以指定一个进程进入另一个进程的ns docker提供了：-net参数 让你启动一个容器并“加入”到另一个容器的net ns； –net=host，不会启动net ns，就意味会和宿主机直接共享网络栈docker run -it –net container:4ddf4638572d busybox ifconfig docker volume原理： 就算开启了 Mount ns，在执行 chroot（或者 pivot_root）之前，容器进程一直可以看到宿主机上的整个文件系统 指定方式 docker run -v /test … ——默认在宿主机上创建一个临时目录 /var/lib/docker/volumes/[VOLUME_ID]/_data，然后把它挂载到容器的 /test 目录上 docker run -v /home:/test … 相关执行顺序：容器启动 –&gt; 5合1准备好容器的roofs –&gt; /home挂载到/var/lib/docker/aufs/mnt/[可读写层 ID]/test （此时mount ns已开启，挂载事件只在这个容器里可见，在宿主机上看不见容器内部的这个挂载点，保证了容器的隔离性不会被 Volume 打破）在复习一下？？？inode知识盲区？？？–&gt;chroot系统调用 找的顺序：启动–&gt;docker volume ls 第一个id –&gt;ls /var/lib/docker/volumes/id/_data/ 08inode知识盲区 容器声明的 Volume 的挂载点虽然出现在读写层，但容器 Volume 里的信息，并不会被 docker commit 提交掉；但这个挂载点目录 /test 本身，则会出现在新的镜像当中","categories":[{"name":"Docker容器","slug":"Docker容器","permalink":"https://jiac3366.github.io/categories/Docker%E5%AE%B9%E5%99%A8/"}],"tags":[]},{"title":"CPU上下文切换（下）","slug":"Linux性能优化/3 CPU上下文切换（下）","date":"2021-10-13T12:07:57.248Z","updated":"2021-10-14T15:59:22.621Z","comments":true,"path":"2021/10/13/Linux性能优化/3 CPU上下文切换（下）/","link":"","permalink":"https://jiac3366.github.io/2021/10/13/Linux%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/3%20CPU%E4%B8%8A%E4%B8%8B%E6%96%87%E5%88%87%E6%8D%A2%EF%BC%88%E4%B8%8B%EF%BC%89/","excerpt":"","text":"vmstat用来分析系统的内存使用情况,也常用来分析CPU 上下文切换和中断的次数 cs（context switch）是每秒上下文切换的次数。 in（interrupt）则是每秒中断的次数。 r（Running or Runnable）是就绪队列的长度，也就是正在运行和等待 CPU 的进程数。 若大于CPU数说明存在CPU竞争 b（Blocked）则是处于不可中断睡眠状态的进程数 us(user) sy 系统CPU使用率 进一步每个进程的详细情况 使用pidstatpidtstat -w 5 隔5s输出一组数据 单位: 次/秒-w 参数表示输出进程切换指标，而 -u 参数则表示输出 CPU 使用指标默认显示进程指标数据，加-t才输出线程指标 ——pidstat -wt 1 cswch，自愿上下文切换，eg: 资源不足 nvcswch非自愿上下文切换，eg:时间片耗尽 sysbench 是一个多线程的基准测试工具，一般用来评估不同系统参数下的数据库负载情况sysbench –threads=10 –max-time=300 threads run pidstat 只是一个进程的性能分析工具，而中断发生在内核态，怎样才能知道中断发生的类型呢？","categories":[{"name":"Linux性能优化","slug":"Linux性能优化","permalink":"https://jiac3366.github.io/categories/Linux%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/"}],"tags":[]},{"title":"CPU上下文切换（上）","slug":"Linux性能优化/2 CPU上下文切换（上）","date":"2021-10-12T12:10:12.922Z","updated":"2021-10-14T15:59:05.382Z","comments":true,"path":"2021/10/12/Linux性能优化/2 CPU上下文切换（上）/","link":"","permalink":"https://jiac3366.github.io/2021/10/12/Linux%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/2%20CPU%E4%B8%8A%E4%B8%8B%E6%96%87%E5%88%87%E6%8D%A2%EF%BC%88%E4%B8%8A%EF%BC%89/","excerpt":"","text":"操作系统管理的“任务”有哪些？ 进程和线程 硬件触发信号 系统负载升高因素之一：上下文切换频繁，缩短进程真正运行的时间 开销排名：进程上线文切换&gt;同进程线程上线文切换&gt;中断上线文切换&gt;内核模式切换&gt;协程上线文切换&gt;用户态函数调用上下文切换 根据“任务”不同，上下文切换也就有不同的场景 进程上下文切换 进程既可以在用户空间运行，又可以在内核空间中运行。 和系统调用（特权模式切换）的区别： 1、进程上下文切换，是指从一个进程切换到另一个进程运行，而系统调用过程中一直是同一个进程在运行。 2、切换的资源 系统调用的过程发生了 2次CPU 上下文切换。每次切换CPU寄存器和内核状态（内核资源）。第一次：CPU 寄存器先保存原来用户态的指令位置，为了执行内核态代码， 需要更新为内核态指令的新位置。最后跳转到内核态运行内核任务。第二次同理。 进程上下文切换不仅切换CPU寄存器和内核状态，还需要切换虚拟内存、用户栈、全局变量（用户资源），当虚拟内存刷新后，TLB（负责从虚拟地址转换到物理地址）也要刷新。 什么时候会切换进程上下文？调度算法学一波！！ 进程时间片耗尽 进程需要的内存（系统资源）不满足–&gt;被挂起 主动sleep –&gt;被挂起 更高优先级的来了–&gt;被挂起 硬件中断发生–&gt;被挂起 线程上下文切换 线程上下文分2种 前后的线程不属于同一个进程–&gt;等同进程切换 前后的线程属于同一个进程–&gt;只切换线程的栈、寄存器等不共享的资源 中断上下文切换 中断上下文只包括内核态中断处理程序执行所必需的状态（只发生在内核态），包括 CPU 寄存器、 内核堆栈、硬件中断参数等，并不涉及到进程的用户态，所以即便硬件中断打断了进程的执行，也不用保存和恢复这个进程的虚拟内存、全局变量等用户态资源.","categories":[{"name":"Linux性能优化","slug":"Linux性能优化","permalink":"https://jiac3366.github.io/categories/Linux%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/"}],"tags":[]},{"title":"各种锁","slug":"操作系统/线程同步","date":"2021-10-04T04:27:43.200Z","updated":"2021-10-14T15:57:55.380Z","comments":true,"path":"2021/10/04/操作系统/线程同步/","link":"","permalink":"https://jiac3366.github.io/2021/10/04/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E7%BA%BF%E7%A8%8B%E5%90%8C%E6%AD%A5/","excerpt":"","text":"忙等待锁-自旋锁 当获取不到锁时，线程就会⼀直 wile 循环，不做任何事情，所以就被称为「忙等待锁」，也被称 为⾃旋锁这是最简单的⼀种锁，⼀直⾃旋，利⽤ CPU 周期（占用着CPU），直到锁可⽤。在单处理器上，需要抢占式的调度器（即 不断通过时钟中断⼀个线程，运⾏其他线程）。否则，⾃旋锁在单 CPU 上⽆法使⽤，因为⼀个⾃旋的线程 永远不会放弃 CPU。？ 无等待锁 当没获取到锁的时候，就把当前线程放⼊到锁的等待队列，然后执⾏调度程序，把 CPU 让给其他线程执⾏","categories":[{"name":"操作系统","slug":"操作系统","permalink":"https://jiac3366.github.io/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"}],"tags":[]},{"title":"HTTP的缓存代理","slug":"透视HTTP协议/HTTP的缓存代理","date":"2021-10-04T03:11:25.120Z","updated":"2021-10-21T16:14:53.714Z","comments":true,"path":"2021/10/04/透视HTTP协议/HTTP的缓存代理/","link":"","permalink":"https://jiac3366.github.io/2021/10/04/%E9%80%8F%E8%A7%86HTTP%E5%8D%8F%E8%AE%AE/HTTP%E7%9A%84%E7%BC%93%E5%AD%98%E4%BB%A3%E7%90%86/","excerpt":"","text":"HTTP缓存功能主要由proxy server实现 client和proxy缓存控制的区别因为proxy server面对多client，所以origin server要对他作多点限制 区别是客户端or代理的缓存 若是客户端，用cache-control: private标识 若是代理，用cache-control: public 区别cache验证的字段 代理使用proxy_revalidate而不是must_revalidate,要求代理的缓存过期后回源server验证，client不回源 区别cache生存时间字段 使用s-maxage限定缓存在代理上能存多久，client仍然使用max-age 代理专属属性：no-transform，不准对缓存的数据做任何手脚，甚至是优化 详细请看20/21的流程图 客户端的缓存控制补充 max-stale=3: 废旧度要小于3天，至多max-age过期3天还能使用 min-fresh=4: 新鲜度要大于4天，max-age前4天内都不使用 only-if-cached: 只接受代理的缓存，不接受源 代理如何知道改次请求是否与上次的请求匹配 vary字段——“vary字段记录下一些字段，这些字段是响应这个请求结果的依据”，所以代理收到带vary会提取里面的请求头计算hash，存入缓存或与已有的缓存作匹配 删除URI对应的缓存数据 自定义请求方法“PURGE”发给代理（?） 试着自己画出缓存的流程图","categories":[{"name":"HTTP","slug":"HTTP","permalink":"https://jiac3366.github.io/categories/HTTP/"}],"tags":[]},{"title":"HTTP的代理服务","slug":"透视HTTP协议/HTTP的代理服务","date":"2021-10-04T02:46:13.762Z","updated":"2021-10-21T16:14:53.709Z","comments":true,"path":"2021/10/04/透视HTTP协议/HTTP的代理服务/","link":"","permalink":"https://jiac3366.github.io/2021/10/04/%E9%80%8F%E8%A7%86HTTP%E5%8D%8F%E8%AE%AE/HTTP%E7%9A%84%E4%BB%A3%E7%90%86%E6%9C%8D%E5%8A%A1/","excerpt":"","text":"代理头字段：Via（请求头/响应头都有） 谁转发了报文，就在报文的Via字段接着加上自己的IP? X-Forwarded-For和X-Real-IP若只有1层代理，2个字段一样 X-Forwarded-For追加的是请求方的IP——“为谁而转发”，最左边的即为client的IP X-Real-IP只记录client的IP X-Forwarded要修改HTTP内容，性能低下，且在HTTPS中不能实现","categories":[{"name":"HTTP","slug":"HTTP","permalink":"https://jiac3366.github.io/categories/HTTP/"}],"tags":[]},{"title":"HTTP的缓存控制","slug":"透视HTTP协议/HTTP的缓存控制","date":"2021-10-04T02:08:47.530Z","updated":"2021-10-21T16:14:53.686Z","comments":true,"path":"2021/10/04/透视HTTP协议/HTTP的缓存控制/","link":"","permalink":"https://jiac3366.github.io/2021/10/04/%E9%80%8F%E8%A7%86HTTP%E5%8D%8F%E8%AE%AE/HTTP%E7%9A%84%E7%BC%93%E5%AD%98%E6%8E%A7%E5%88%B6/","excerpt":"","text":"格式：Cache-Control: [field]=[value] 响应端 Cache-Control的max-age与Cookie的Max-Age2者有点相似 Cache-Control的max-age为生存时间，起点是报文的创建时刻（包含网络链路传输时间） 但Cookie的Max-Age以报文收到的时间作为起点 请求端 浏览器也可以使用Cache-Control F5: Cache-Control:max-age=0，故client没用缓存 Ctrl+F5: Cache-Control:no-store( 通常与F5一样，要看server怎么理解 ) 浏览器的前进和后退——跳转重定向，client无带Cache-Control，只用最基本请求头，不再进行网络通信 如何提高client更新缓存的效率？ （1）发2次请求：先发HEAD验证，若有改动，再GET （2）使用If开头的条件请求字段（2合1）最常用If-Modified-Since、If-None-Match， ??? Cache-Control其他控制缓存的属性： no_store: 不许缓存 no_cache: 允许缓存——但使用缓存前先与server验证当前cache是否是最新的cache，然后干什么你懂的啦 must_revalidate：允许缓存——缓存不过期就允许使用，但过期后如果还想要用必须与server验证(2) 优先级：Cache-Control &gt;Expires","categories":[{"name":"SQL","slug":"SQL","permalink":"https://jiac3366.github.io/categories/SQL/"}],"tags":[]},{"title":"Cookie","slug":"透视HTTP协议/Cookie","date":"2021-10-04T01:37:19.327Z","updated":"2021-10-21T16:14:53.696Z","comments":true,"path":"2021/10/04/透视HTTP协议/Cookie/","link":"","permalink":"https://jiac3366.github.io/2021/10/04/%E9%80%8F%E8%A7%86HTTP%E5%8D%8F%E8%AE%AE/Cookie/","excerpt":"","text":"Cookie有效期用Expires, Max-Age属性设置server过于健忘，有时会设多条cookie，用“；”分隔 Expires和Max-Age Expires为截止日期，是个绝对时间，如果更改本机时间可能会造成失效. Max-Age+报文收到的时间即等于失效时间，优先使用 Domain和Path组成Cookie作用域让client发送Cookie给指定URI(?) Domain指定所属域 Path指定路径，一般用”/“，代表域名所有的路径都使用 HttpOnly 防止客户端使用非HTTP方式 (例如Js) 获取Cookie——预防XSS SameSite:value（?）可以防XSRF 值为Strict：不能随跳转URI跨站发送 值为Lax：允许GET/HEAD等安全方法，但禁止POST跨站发送 Secure 仅能用HTTPS传输Cookie，但Cookie在Browser明文存在 Cookie最大作用：身份识别-广告追踪 google给你贴个Cookie，别的网站通过读取它的Cookie（第三方Cookie）对你推广告 会话Cookie 不设置Expires和Max-Age，浏览器一关就失效，过期时间显示为“session”或“N/A” Cookie大小&lt;=4k，以数据库记录(sqlite)存放","categories":[{"name":"HTTP","slug":"HTTP","permalink":"https://jiac3366.github.io/categories/HTTP/"}],"tags":[]},{"title":"重定向和跳转","slug":"透视HTTP协议/重定向和跳转","date":"2021-10-04T01:18:14.240Z","updated":"2021-10-14T15:54:49.937Z","comments":true,"path":"2021/10/04/透视HTTP协议/重定向和跳转/","link":"","permalink":"https://jiac3366.github.io/2021/10/04/%E9%80%8F%E8%A7%86HTTP%E5%8D%8F%E8%AE%AE/%E9%87%8D%E5%AE%9A%E5%90%91%E5%92%8C%E8%B7%B3%E8%BD%AC/","excerpt":"","text":"响应报文中有字段：Location: [URI] 301永久重定向：意味着原URI不再存在了，今后必须用新的URI，浏览器可能会更新书签等，爬虫也会更新 302临时重定向：浏览器和爬虫会认为临时不可用原URI，执行简单跳转 303.307.308类似，但有细节上的约束，慎用！ 重定向是server控制浏览器的手段 域名更换/网站维护等避免404出现 增加多个类似的域名入口再跳到主站点 重定向场景 301-涉及到重大改变的，对SEO也挺重要 302-涉及到临时维护跳转到通知页或服务降级（双十一促销） 一个跳转会有2次“请求-应答”(?) 浏览器的前进和后退——跳转重定向（?）","categories":[{"name":"HTTP","slug":"HTTP","permalink":"https://jiac3366.github.io/categories/HTTP/"}],"tags":[]},{"title":"HTTP连接管理","slug":"透视HTTP协议/HTTP连接管理","date":"2021-10-03T05:07:24.334Z","updated":"2021-10-21T16:14:53.691Z","comments":true,"path":"2021/10/03/透视HTTP协议/HTTP连接管理/","link":"","permalink":"https://jiac3366.github.io/2021/10/03/%E9%80%8F%E8%A7%86HTTP%E5%8D%8F%E8%AE%AE/HTTP%E8%BF%9E%E6%8E%A5%E7%AE%A1%E7%90%86/","excerpt":"","text":"长连接Connection:”Keep-alive”长连接：第一次请求后的请求复用第1次请求打开的TCP连接 1.1默认启用长连接,client发送**Connection:”Keep-alive”**表示使用长连接，但server不会管这么多只要支持就发这字段. server一般不主动关闭连接，可以设置Nginx的策略关闭 keepalive_timeout 超时时间 keepalive_requests 长连接可发的最大请求数 如何优化缓解HTTP1.1队头阻塞——“请求-应答模型导致”类似上班打卡，只要有一个人打不上卡，后面都等着 “并发连接”（买多几台打卡机）=&gt;client同时对1server发起多个长连接，一般一个client最多并发6~8个长连接 “域名分片”（前台放不下这么多打卡机，在每个楼层放吧），本质上也是数量解决，HTTP对一个域名并发有限制(?)，那就多开几个域名，绑定到同一个服务器 PS： 长连接最重要是区分多个报文的开始和结束，使用Content-Length正确标记报文结束。对于流式传输，必须用分块传输编码(Transfer-Encoding:chunked?) Connection:Upgrade + 状态码101表示协议升级表示从HTTP切换到WebSocket","categories":[{"name":"HTTP","slug":"HTTP","permalink":"https://jiac3366.github.io/categories/HTTP/"}],"tags":[]},{"title":"数据类型与编码","slug":"透视HTTP协议/数据类型与编码","date":"2021-10-03T04:41:00.843Z","updated":"2021-10-21T16:14:53.701Z","comments":true,"path":"2021/10/03/透视HTTP协议/数据类型与编码/","link":"","permalink":"https://jiac3366.github.io/2021/10/03/%E9%80%8F%E8%A7%86HTTP%E5%8D%8F%E8%AE%AE/%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B%E4%B8%8E%E7%BC%96%E7%A0%81/","excerpt":"","text":"数据类型与编码 HTTP告诉上层应用这是什么数据——数据类型、压缩格式 MIME数据类型 压缩格式 gzip(GUN zip压缩格式 最流行) Nginx gzip on仅仅对文本数据有效 deflate(zlib压缩格式) br(专门HTTP优化的压缩算法) 相关字段（Accept-xxx代表想要对方要干的，Content-xxx代表自己是这么干的） Accept(client告诉server可接受的MIME类型) Content-Type（server告诉client实际发了啥MIME） eg: text/html; charset=utf-8 Accept-Encoding（client支持的压缩格式） Content-Encoding（server实际用的压缩格式） 以上2个不发说明 client不支持压缩 server也没有压缩 语言类型与编码 浏览器能解析多种数据类型，但又如何让它显示成不同国家的自然语言呢？ 相关字段 Accept-Language type-subtype:en-GB, en-US, zh-CN Content-Language(少用) Accept-Charset(少用) 注意：没有Content-Charset “Content-Charset”相关内容在Content-Type（server告诉client实际发了啥MIME） 内容协商优先级 分号权重比逗号低 服务器响应的结果 使用vary字段记录响应这个请求结果的依据","categories":[{"name":"HTTP","slug":"HTTP","permalink":"https://jiac3366.github.io/categories/HTTP/"}],"tags":[]},{"title":"","slug":"透视HTTP协议/1透视HTTP协议","date":"2021-10-03T03:32:56.814Z","updated":"2021-10-04T03:32:22.163Z","comments":true,"path":"2021/10/03/透视HTTP协议/1透视HTTP协议/","link":"","permalink":"https://jiac3366.github.io/2021/10/03/%E9%80%8F%E8%A7%86HTTP%E5%8D%8F%E8%AE%AE/1%E9%80%8F%E8%A7%86HTTP%E5%8D%8F%E8%AE%AE/","excerpt":"","text":"透视HTTP协议 HTTP1.1缺点 请求-应答模式，会造成同步阻塞 以文本格式传输Header，效率下降 数据类型与编码 HTTP传输大文件 HTTP连接管理 重定向和跳转 Cookie HTTP的缓存控制 HTTP的代理服务 HTTP的缓存代理 HTTPS 对称与非对称加密 数字签名与证书 … HTTP2特性概览 HTTP3展望 Nginx、OpenResty WAF CDN Websocket：沙盒里的TCP HTTP性能优化","categories":[],"tags":[]},{"title":"HTTP传输大文件","slug":"透视HTTP协议/HTTP传输大文件","date":"2021-10-03T03:09:44.579Z","updated":"2021-10-21T16:14:53.681Z","comments":true,"path":"2021/10/03/透视HTTP协议/HTTP传输大文件/","link":"","permalink":"https://jiac3366.github.io/2021/10/03/%E9%80%8F%E8%A7%86HTTP%E5%8D%8F%E8%AE%AE/HTTP%E4%BC%A0%E8%BE%93%E5%A4%A7%E6%96%87%E4%BB%B6/","excerpt":"","text":"Transfer-Encoding与Content-Length互斥 在响应头部Transfer-Encoding:chunked表示 交互流程： Server用Accept-Ranges:bytes告知client支持范围请求（视频快进功能）不支持干脆不发 client使用Range:bytes=x-y 告知要的范围eg:一个100字节文件, client要前10字节：Range:bytes=0-10 server收到Range字段后先检查合法性：非法返416，合法返206，并在头字段加Content-Range:byes=x-y client也可以一次性请求多个范围，响应报文数据类型字段为multipart/byteranges表示响应报文体由多段字节序列组成 多段序列报文的格式与分块传输有一点区别","categories":[{"name":"HTTP","slug":"HTTP","permalink":"https://jiac3366.github.io/categories/HTTP/"}],"tags":[]},{"title":"进程间通信","slug":"操作系统/进程间通信方式","date":"2021-09-15T14:56:09.563Z","updated":"2021-09-15T14:56:58.773Z","comments":true,"path":"2021/09/15/操作系统/进程间通信方式/","link":"","permalink":"https://jiac3366.github.io/2021/09/15/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E8%BF%9B%E7%A8%8B%E9%97%B4%E9%80%9A%E4%BF%A1%E6%96%B9%E5%BC%8F/","excerpt":"","text":"进程间通信 管道 通信⽅式效率低，不适合进程间频繁地交换数据，匿名管道跟随进程的生命周期 在 shell ⾥⾯执⾏ A | B 命令的时候，A 进程和 B 进程都是 shell 创建出来的⼦进程 如果要进程双向通信，要创建2个管道（不然父进程fork子进程也把管道读写描述符复制了，2者对同一个管道写读造成混乱） ​进程写⼊读取的数据都经过内核 | 匿名管道 特殊文件 在内存 mkfifo myPipe 创建命名管道 ls在文件系统能看到文件类型是p(pipe) 消息队列 相比管道，可以频繁交换数据 ​消息队列跟随内核的生命周期，会有两个宏定义 MSGMAX 和 MSGMNB ，它们以字节为单位，分别定义了⼀条消息的最⼤⻓度和⼀个队列的最⼤⻓度 缺点：⼀是通信不及时，二不适合⽐较⼤数据的传输，三存在⽤户态与内核态之间的数据拷⻉开销 共享内存 拿出⼀块虚拟地址空间来，映射到相同的物理内存中 信号量(p191) 防⽌多进程竞争共享资源造成的数据错乱的保护机制，主要⽤于实现进程间的互斥与同步，⽽不是⽤于缓存进程间通信的数据。 信号初始化为 1 ，是互斥信号量 在任何时刻只有⼀个进程在访问 信号初始化为 10，是同步信号量 保证进程 A 应在进程 B 之前执⾏ 信号 进程间通信机制中唯⼀的异步通信机制 Ctrl+C 产⽣ SIGINT 信号，表示终⽌该进程 Ctrl+Z 产⽣ SIGTSTP 信号，表示停⽌该进程，但还未结束 Socket Socket 通信不仅可以跨⽹络与不同主机的进程间通信，还可以在同主机上进程间通信 UDP 是没有连接的，不需要调⽤ listen 和 connect，要bind socket类型:6种（协议族：本机/Ipv4/Ipv6，通信特性：字节流/数据报） 本地字节流 socket 和 本地数据报 socket 在 bind 的时候，不像 TCP 和 UDP 要绑定 IP 地址和端⼝，⽽是绑定⼀个本地⽂件，这也就是它们之间的最⼤区别。","categories":[{"name":"操作系统","slug":"操作系统","permalink":"https://jiac3366.github.io/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"}],"tags":[]},{"title":"后端存储知识","slug":"后端存储知识","date":"2021-08-14T10:09:16.833Z","updated":"2021-10-14T15:59:59.640Z","comments":true,"path":"2021/08/14/后端存储知识/","link":"","permalink":"https://jiac3366.github.io/2021/08/14/%E5%90%8E%E7%AB%AF%E5%AD%98%E5%82%A8%E7%9F%A5%E8%AF%86/","excerpt":"","text":"CAP理论 不关注单节点系统，也不关注没有数据共享的多节点系统 一致性 保证可用性AP 可用性 保证一致性 分区容忍性（一定需要） 事务的ACID特性（AD必须要保证） A 原子性 C 一致性 I 隔离性 D 持久性C 有流水就有余额变化I 没提交的事务对于其他事务不可见 实现：（不可能100%实现ACID） 数据库事务——四个隔离级别 区分RC(读提交)和RR(可重复读)——一个事务能否读到其他事务对数据已提交的更新 能： RC、不能：RR（mysql默认） 幻读很少遇到也基本不会影响数据准确性RR屏蔽掉了其他事务对真实数据的修改，自己无法查询，但实际上数据已存在或已经修改 兼顾【性能、并发、一致性】的交易方案： 1、给账户余额表增加一个 log_id 属性，记录最后一笔交易的流水号 2、首先开启事务，查询并记录当前账户的余额和最后一笔交易的流水号 3、然后写入流水记录 4、再更新账户余额，但有条件限定：只有流水号等于之前查询出的流水号时才更新 5、然后检查更新余额的返回值，如果更新成功就提交事务，否则回滚事务。 分布式事务——2PC、3PC、TCC、Saga 和本地消息表 下面例子展示不同模型之间的事务交互​分布式事务的“分布式”可以是多主机的系统的事务，也可以是在单机中的不同系统（模型） 实现1：2PC（二阶段提交） 例如:强一致性&amp;并发低场景，订单表（订单系统，下单并绑定消费券id）和消费券表（促销系统，对消费券改为已使用）​2PC 引入了一个事务协调者的角色，来协调两个系统的数据更新操作保持一致，要么都更新成功，要么都更新失败 1、准备阶段：协调者叫各方做准备工作（除了事务提交的所有工作） 2、提交阶段：收到各方”待命”通知后，统一发号令: “提交” 异常处理: 在准备阶段，如果任何一步出现错误或者是超时，协调者就会给两个系统发送“回滚事务”请求 如果已进入提交阶段，整个分布式事务只能成功，反复重试，直到提交成功。如果这个阶段发生宕机，包括两个数据库宕机或者订单服务、促销服务所在的节点宕机，还是有可能出现订单库完成了提交，但促销库因为宕机自动回滚，导致数据不一致的情况。 ps: 2PC 这个协调服务最好和订单服务或者优惠券服务放在同一个进程里，进程更少故障点更少性能更好 缺点：执行过程会阻塞服务端的线程和数据库的会话，协调者是一个单点，宕机会导致事务超时 实现2：本地消息表(可以存MQ/DB/File) 例如:适用在没依赖其他资源(eg:下单不需要锁库存) 实时性要求不高场景，订单表和购物车表 1、在执行这个数据库事务过程中，在本地记录一条消息。这个消息就是一个日志，内容就是“清空购物车”这个操作。我们可以让订单库的事务，来保证记录本地消息和订单库的一致性。完成后可以给客户端返回成功响应 2、用一个异步的服务，读取刚刚记录的清空购物车的本地消息，调用购物车系统的服务清空购物车。购物车清空之后，把本地消息的状态更新成已完成就可以了。异步清空购物车这个过程中，如果操作失败了，可以通过重试来解决。 高并发应对方法（并发高-&gt;分库） 避免重复请求、解决ABA（幂等性问题：其任意多次执行所产生的影响均与一次执行的影响相同） 重复请求：后端提供生成订单号（返回值就是新的，全局唯一的）的服务，订单号作为订单表的主键，前端每次提交就自动带上 ABA：加入版本号字段 Redis保护DB 了解常见缓存策略 Read/Write Through Cache Aside （更好，写操作与Read/Write Through不同） 分库 读写分离 读多写少 与用户关联不大的数据，可以用Redis挡，但是涉及到用户订单等关联大的数据呢？主节点读写兼顾 从节点只读做热备 主从同步问题 主库提交事务 从库复制（mysql半同步复制）mysql5.7可以配置至少几个从节点复制后就返回相应​也可以配置提交事务和复制的先后顺序​默认是先等待复制，再提交事务（同步复制）AFTER_SYNC异步复制有可能丢数据：从节点在复制中主节点挂了 多从库的SLB和高可用方案：HAProxy+KeepAlived 主从延迟问题 主库数据更新后是否需要立刻查询？是：把更新后的查合并成一个微服务放在一个事务中(？)，强制更新后的查打在主库否：更新后几秒后再返回 需要把‘更新、查询’合并成一个事务，所以更新后的查询会被路由到主库 不需要更新后过几秒返回–&gt;下单后等几秒​ 实现： 纯手工方式 组件方式（推荐）得看编程语言的是否有读写分离组件 代理方式（主流）不方便修改应用的代码的情况下 数据量大的应对方法（数据量大-&gt;分表） “拆”——分出历史表 归档历史数据，分出历史订单表如何删除3个月前的订单？详看14 最后一招——用“分片”分表“分片”：通过某字段找到数据在哪个库哪个表eg:在订单号的后几位加入用户ID 就可以根据用户查出订单在哪个库哪个表eg:店铺订单,可以复制一个订单DB，把店铺ID设为Sharding ID​根据什么属性分片就要根据什么属性查，所以对查询会作很多限制 分片算法 时间范围分片易出现热点问题，适用于数据多并发低的系统 订单表hash分片取ID与分片数的模 一致性hash算法hash算法都是为了均匀分布数据 查表法eg:数据可视化系统:商品名映射到某个表 Redis Cluster 存储海量数据 低成本中小集群 如何存？ 数据key与16384取模，余数为所在槽 通过节点的映射表找真正节点在每个节点存一个槽与节点的映射关系 如何保持高可用？ 对每个分片增加从节点，做主从复制从节点一般是热备 也可以读写分离 MySQL to Redis Kafka/RocketMQ Binlog实时更新Redis(更通用)实时解析Binlog –&gt;开源项目：Canal 如何降级或补偿应对数据出现不一致 跨数据系统实时同步 详见笔记p19 MQ多分区存储binlog因果关系的binlog需要hash到同1分区 对面系统的同步程序多线程消费MQ 海量数据存储方案 分布式存储系统：对象存储、HDFS 点击流、监控日志数据 Kafka、HDFSkafka高吞吐 不无限存 查询能力较差​HDFS查询能力好 无限存储 分布式流Pulsar/Bookkeeper、时序数据 (监控数据)InfluxDB/OpenTsDB 海量数据提高查询速度 GB级 给分析系统单独配MySQL 10GB HBase Cassandra ClickHouse 列式DB ES 成本高 内存占用大 但推荐 TB级 定期聚合计算好存在HDFS 再配合Map-Reduce、Spark、Hive做Data聚合计算","categories":[{"name":"后端架构","slug":"后端架构","permalink":"https://jiac3366.github.io/categories/%E5%90%8E%E7%AB%AF%E6%9E%B6%E6%9E%84/"}],"tags":[]},{"title":"SQL必知必会","slug":"SQL必知必会","date":"2021-08-14T09:41:44.577Z","updated":"2021-10-14T15:53:42.273Z","comments":true,"path":"2021/08/14/SQL必知必会/","link":"","permalink":"https://jiac3366.github.io/2021/08/14/SQL%E5%BF%85%E7%9F%A5%E5%BF%85%E4%BC%9A/","excerpt":"","text":"入门 SQL执行顺序 FROM ON JOIN WHERE GROUP BY HAVING SELECT DISTINCT 聚合函数 ORDER BY LIMIT 左表大用 IN, 右表大用EXIST，下图结果相同：WHERE条件加和不加效果一致？ OLTP实时性会比较高 随时需要CRUD 适合行式存储,OLAP用于汇总和分析 列式存储易于压缩（相邻数据的数据类型都是一样）可以降低I/O InnoDB COUNT(*)/(1) 统计行数时间复杂度为O(N) MyISAM为O(1)– &gt;MyISAM 的一致性由表级锁维护 数据表有一个 meta 信息存储了row_count值,尽量在数据表上建立二级索引，系统会自动采用key_len小的二级索引进行扫描（因为为主键采用的索引是聚簇索引，包含的信息多，会慢） 排序的字段应该加索引 进阶 B树和B+树区别？ 数据存储位置B树的非叶子节点包含数据，而B+树所有数据在叶子结点上 数据查询过程B+树会不断递归地在非叶子节点（非叶子节点上有索引键和指向下一页的指针）上做二分查找，直到找到叶子结点，最后在叶子节点上做B+树检索[页]查询数据过程 B+树特性：B+树可以顺序地访问非叶子节点，做到数据的范围查询1个非叶子结点key指向的数据在它左右2边key所指向的数据的范围之内 Hash索引 hash索引不能用于Order/group by，不能支持最左前缀原则（多个key一起计算hash），不支持模糊查询 适用key-value场景，当mysql某个条件查询频繁，就给这个条件字段生成自适应索引 适用索引的场景 Where字段/value唯一的字段/Distinct字段/Join连接字段 同时进行Group A和Order B的查询时，应使用对应顺序的(A,B)联合索引 不适用索引的场景 数据太少 数据重复太多 数据更新频繁 索引失效场景 字段进行表达式/函数计算 WHERE中使用OR的2个字段没有都建立索引 LIKE 直接跟% 索引列与NULL进行判断(所以要把字段设为非空) (A,B)的联合索引用了B查询 从数据页理解B+树查询 页&lt;区(连续)&lt;段&lt;表空间 区：一个区有64个连续的页，默认页大小为16k，所以一个区1MB 段：区在操作系统中是连续分配的空间，即一个段区在段中不一定是连续的，段也是数据库分配的单位，例如创建表段、索引段 表空间：一个DB由1个或多个表空间（逻辑容器）组成，一个表空间有1个或多个段，其中InnoDB共享（独立）表空间：多（一）张表用一个表空间 InnoDB页结构 不同DBMS页结构不同，通常一页有上千条记录 (1) 文件头 文件头 38B 带有上下文的指针 页头 56B 记录页的状态信息 (2) 页记录 最大最小记录 26B 用户记录 空闲记录 (3)页目录（索引）将(2)的记录分成若干分组，在页目录存对应数量的slot，每个slot记录每个分组的结尾位置，充当索引的作用二分查找记录（空间换时间） (4)文件尾 8B其中的校验和会与文件头的校验值作对比 B+树检索[页]查询数据过程 (1)逐层检索B+树直至找到叶子节点 (2)从页目录的槽查找数据所在的分组(二分查找) (3)找到组后遍历单链表（记录之间是链表链接） 从磁盘I/O角度理解SQL查询的成本 查看缓冲池的大小，当缓冲池大小&gt;1G时，缓冲池的实例数才可以修改[修改缓冲池大小：set global innodb_buffer_pool_size = 134217728] 数据页加载的3种方式 查询速度：缓冲池&gt;内存&gt;磁盘 内存读取（1次读取1条记录 1ms） 随机读取（在磁盘找页，10ms，6ms等磁盘，3ms排队，1ms传输） 顺序读取（批量读取）存储介质物理特性：顺序读&gt;多次随机读，设磁盘吞吐量40MB/s，40M/16kB = 0.4ms，每秒读约2560页​ 统计SQL查询成本，可以看到上一条SQL要读取页的数量[SHOW STATUS LIKE ‘last_query_cost’] 三星索引 … 关于锁 共享锁和排他锁 资源加上共享锁（S锁）–&gt;只读，加上排他锁（X锁）–&gt;读写均不可操作当SELECT时，默认不加锁（快照读）；当INSERT/DELETE/UPDATE时，数据库会对记录加X锁（当前读） 加/解锁方式 表 共享锁 LOCK TABLE product_comment READ; / UNLOCK TABLE; 排他锁 LOCK TABLE product_comment WRITE; /UNLOCK TABLE; 数据行 共享锁 SELECT xx FROM table WHERE user_id = 912178 LOCK IN SHARE MODE 排他锁 SELECT xx FROM table WHERE user_id = 912178 FOR UPDATE 意向共享/排他锁：当事务操作某些记录的数据，会在表上添加对应的意向锁，提示其他事务有人”占”了表中的某些记录 因为共享锁允许其他事务加共享锁(共享锁不排他)，多个读锁可能出现死锁当第二个事务使用UPDATE等操作加上排他锁的操作时，会不停地等待，超时 乐观锁和悲观锁 是程序员对待数据并发风险的一种态度体现 乐观锁（认为别人不会同时写入），使用版本机制或时间戳实现控制同一数据被“同时修改”版本机制：后端存储知识 中的【区分 RR(可重复读)/RC(读提交)】小节的解决方案 悲观，用数据量自身的锁机制 死锁 因为在事务（进程）中，锁的获取是逐步的 有锁的存在，死锁就有可能，eg:2个事务都对资源获取共享锁，结果都没法更新操作 如何避免死锁 若事务涉及多个表或一个表的大部分数据时，可以一次性锁定多个表或整个表 不同事务并发多张表，可以约定它们访问表的顺序(? 事务隔离如何实现？ MVCC可以解决什么问题的？ 优点： 通过版本号解决数据是否显示，即使读不加锁也实现数据隔离 读写互不阻塞，并发提高 解决一致性读（快照读）问题，查数据时只能读到这个时间点前事务提交的结果 快照读/当前读 快照读：不加锁的select 当前读：加锁的select和增删改就是对数据行的共享锁和排他锁 MVCC = Undo log(mv) + ReadView(cc) Undo log操作这个数据的事务ID 遍历行记录的回滚指针可以查历史快照​ ReadView RR与RC在读取ReadView中存在不同 RC每次读都会获取一次ReadView RR会复用第一次读的ReadView所以见不到后面事务提交的数据 InnoDB如何解决幻读 在RR情况下，InnoDB通过Next Key + MVCC解决 行锁种类 记录锁（RC采用），锁记录 间隙锁，锁记录旁，索引与索引之间的空隙 Next Key，等于记录锁+间隙锁 RR级别业务中解决幻读的方案 单数据库事务：参考版本机制：后端存储知识 中的【区分 RR(可重复读)/RC(读提交)】小节的解决方案 多数据库：引入流水功能，流水本身不要出现数据一致性问题，所以字段要包括双方的帐户字段 王争设计模式给出的流水方案–保持数据一致性 查询优化器如何工作 逻辑优化——查询重写属于代数级语法级的优化 物理查询优化——基于代价的估算模型从连接路径中选代价最小的路径 CBO RBO 使用性能分析工具定位SQL执行慢的原因 … InnoDB总结 三大特性：自适应hash、插入缓冲、二次写 自适应hash将B+树索引中的热点数据页的地址存到hash表中,再存到缓冲池缓冲池两大特性：优先对频次高的热数据加载、预读，区别于查询缓存将查询结果缓存下来，8.0已启用 SQL执行过程(server层) 0 连接器 定期断开长连接，占用内存大的查询先断掉，需要再重连 5.7后可以初始化连接，无需重连 1 分析器——词法语法分析+语义分析，生成语法分析树 判断语句正确表列、是否存在 2 优化器——逻辑优化+物理查询优化，生成查询计划。查询优化器如何工作 3 执行器——判断有否权限，有就打开表使用引擎提供的接口查询 联合索引补充 … SQL范式设计——围绕非主属性/主属性是否对于候选键是直接依赖？ 码 = 候选键(唯一确定记录的键)= 所有主键——其包含的所有属性都叫主属性2NF：消除了非主属性对于候选键的部分依赖。3NF：消除了非主属性对于候选键的传递依赖。BCNF：消除主属性对于候选键的部分与传递依赖。 1NF：字段不可拆分，任何的 DBMS 都会满足第一范式 2NF：表中非主属性要和表的候选键有完全依赖关系即两个对象不能掺和在一起，2NF 告诉我们一张表就是一个独立的对象 3NF：任何非主属性都不传递依赖于候选键——保证只能由候选键直接决定非主属性，非主属性不能决定非主属性不能存在非主属性 A 依赖于非主属性 B，非主属性 B 依赖于候选键的情况。 eg：现在有一张学生选课表，包含的属性有学号、姓名、课程名称、分数、系别和系主任 学生和课程要分开 –&gt;不是同一个对象，违反2NF分成Student(学号,姓名,系别)和Course(课程号，课程名称)2个对象中间加个表关联: SC(学号,课程号,分数) 要分成Student(学号,姓名,系别)和Sdept(系别,系主任)，因为学生决定系别，系别又决定系主任–&gt;违反3NF非主属性系主任会传递依赖于学号 BCNF：在 3NF 的基础上消除了主属性对候选键的部分依赖或者传递依赖关系。第22章 反范式设计：通过空间换时间，提升查询的效率 在数据量大情况下 直接在评论表中加入用户名字段 就不用查询2个表 使用场景：冗余信息有价值或者能大幅度提高查询效率的时候，数据仓库在设计上更偏向采用反范式设计。如订单中的收货人信息，包括姓名、电话和地址等需要保存记录，但用户可以轻易修改这些信息 缺点：1.让数据库的设计更加复杂。2.增加系统的维护成本。比如用户每次更改昵称的时候，都需要执行存储过程来更新，如果昵称更改频繁，会非常消耗系统资源 杂谈：候选键就像这一行数据的老大，它能唯一决定这行记录。当然，这条记录有可能有多个老大，候选键中不包含的属性就是小弟们，2NF规定，老大与小弟们的关系，要么1对多，要么多对1，否则就不符合2NF。","categories":[{"name":"SQL","slug":"SQL","permalink":"https://jiac3366.github.io/categories/SQL/"}],"tags":[]}],"categories":[{"name":"MySQL必知必会","slug":"MySQL必知必会","permalink":"https://jiac3366.github.io/categories/MySQL%E5%BF%85%E7%9F%A5%E5%BF%85%E4%BC%9A/"},{"name":"Docker容器","slug":"Docker容器","permalink":"https://jiac3366.github.io/categories/Docker%E5%AE%B9%E5%99%A8/"},{"name":"Linux性能优化","slug":"Linux性能优化","permalink":"https://jiac3366.github.io/categories/Linux%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/"},{"name":"操作系统","slug":"操作系统","permalink":"https://jiac3366.github.io/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"},{"name":"HTTP","slug":"HTTP","permalink":"https://jiac3366.github.io/categories/HTTP/"},{"name":"SQL","slug":"SQL","permalink":"https://jiac3366.github.io/categories/SQL/"},{"name":"后端架构","slug":"后端架构","permalink":"https://jiac3366.github.io/categories/%E5%90%8E%E7%AB%AF%E6%9E%B6%E6%9E%84/"}],"tags":[]}